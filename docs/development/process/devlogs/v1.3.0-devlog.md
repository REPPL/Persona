# DevLog: v1.3.0 - Local Model Foundation

## Overview

v1.3.0 delivers the "Local & Private" milestone with two features enabling fully local persona generation and privacy-preserving data handling.

## Feature Summary

| ID | Feature | Description |
|----|---------|-------------|
| F-112 | Native Ollama Provider | Local LLM inference via Ollama |
| F-113 | PII Detection & Anonymisation | Privacy protection for sensitive data |

## Implementation Narrative

### Phase 1: Ollama Provider (F-112)

The native Ollama provider enables local model inference:

```python
from persona.core.providers import OllamaProvider

# Basic usage
provider = OllamaProvider(model="qwen2.5:72b")
response = provider.generate("Create a persona based on...")

# Auto-detect available models
models = provider.list_available_models()
```

Key components:
- Native HTTP client for Ollama API (no SDK dependency)
- Auto-detection of locally available models via `/api/tags`
- Health check endpoint for connection validation
- Graceful fallback when Ollama not running
- Both sync and async generation support

### CLI Integration

```bash
# Generate with local model
persona generate --input data.csv --provider ollama --model llama3:8b

# List available local models
persona models --provider ollama

# Auto-select best available model
persona generate --input data.csv --provider ollama
```

### Phase 2: PII Detection & Anonymisation (F-113)

Privacy protection using Microsoft Presidio:

```python
from persona.core.privacy import PIIDetector, PIIAnonymiser

# Detection
detector = PIIDetector()
entities = detector.detect(text)

# Anonymisation
anonymiser = PIIAnonymiser(strategy="redact")
result = anonymiser.anonymise(text, entities)
```

Three anonymisation strategies:

```
Original:  "Contact John Smith at john@example.com"
Redact:    "Contact [PERSON] at [EMAIL_ADDRESS]"
Replace:   "Contact Anonymous Person at anonymous@example.com"
Hash:      "Contact a1b2c3d4 at e5f6g7h8"
```

### CLI Commands

```bash
# Scan for PII without modifying
persona privacy scan --input ./data/interviews.csv

# Anonymise data file
persona privacy anonymise --input sensitive.csv --output safe.csv --strategy redact

# Integrated with generate
persona generate --from sensitive.csv --anonymise --anonymise-strategy replace
```

## Technical Highlights

### Ollama API Integration

```python
class OllamaProvider(LLMProvider):
    BASE_URL = "http://localhost:11434"

    async def agenerate(self, prompt: str, **kwargs) -> str:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.base_url}/api/chat",
                json={
                    "model": self.model,
                    "messages": [{"role": "user", "content": prompt}],
                    "stream": False,
                    "options": {"temperature": kwargs.get("temperature", 0.7)}
                },
                timeout=self.timeout
            )
            return response.json()["message"]["content"]

    def list_available_models(self) -> list[str]:
        response = httpx.get(f"{self.base_url}/api/tags")
        return [m["name"] for m in response.json()["models"]]
```

### PII Detection Pipeline

```python
class PIIDetector:
    def __init__(self, language: str = "en", threshold: float = 0.5):
        self.analyzer = AnalyzerEngine()
        self.threshold = threshold

    def detect(self, text: str) -> list[PIIEntity]:
        results = self.analyzer.analyze(
            text=text,
            language=self.language,
            score_threshold=self.threshold
        )
        return [
            PIIEntity(
                type=PIIType(r.entity_type),
                text=text[r.start:r.end],
                start=r.start,
                end=r.end,
                score=r.score
            )
            for r in results
        ]
```

### Graceful Degradation

Both features work without their optional dependencies:

```python
# Without Presidio installed
try:
    from presidio_analyzer import AnalyzerEngine
    PRESIDIO_AVAILABLE = True
except ImportError:
    PRESIDIO_AVAILABLE = False

class PIIDetector:
    def __init__(self):
        if not PRESIDIO_AVAILABLE:
            self._available = False
            return
        # Normal initialisation...

    def detect(self, text: str) -> list[PIIEntity]:
        if not self._available:
            raise PrivacyModuleNotAvailable(
                "Privacy module not installed. "
                "Install with: pip install persona[privacy]"
            )
        # Normal detection...
```

## Testing

| Category | Tests |
|----------|-------|
| Ollama provider | 20 |
| PII entities | 19 |
| PII detector | 15 |
| PII anonymiser | 15 |
| CLI integration | 10+ |
| **Total milestone** | 79+ |
| **Project total** | 2708 |

Tests handle optional dependencies:
- Core tests pass without Ollama running
- Core tests pass without Presidio installed
- Integration tests skipped when dependencies unavailable

## Dependencies

```toml
[project.optional-dependencies]
privacy = [
    "presidio-analyzer>=2.2",
    "presidio-anonymizer>=2.2",
    "spacy>=3.7",
]

# Note: Ollama requires no Python dependencies (HTTP API)
```

## Bug Fixes

### Mock Property for Tests

**Issue**: Mocking `available_models` property on `OllamaProvider` required special handling.

**Fix**: Use internal cache attribute for test overrides:
```python
provider._available_models_cache = ["test:model"]
```

### Provider Configuration Check

**Issue**: Tests checking for "configured providers" failed because Ollama doesn't require API keys.

**Fix**: Updated test to allow Ollama in configured providers list without API key validation.

## CLI Commands Added

```bash
# Privacy scanning
persona privacy scan --input FILE [--threshold N] [--entities TYPES] [--json]

# Privacy anonymisation
persona privacy anonymise --input FILE [--output FILE] [--strategy STRATEGY] [--force]

# Generate with anonymisation
persona generate --from FILE --anonymise [--anonymise-strategy STRATEGY]

# Ollama provider
persona generate --provider ollama [--model MODEL]
persona models --provider ollama
```

## Summary

v1.3.0 establishes the foundation for privacy-preserving persona generation:

- **Ollama provider** enables fully local operation without cloud API calls
- **PII detection** identifies sensitive data before processing
- **Anonymisation** provides multiple strategies for different use cases
- **Graceful degradation** ensures features work without optional dependencies
- **CLI integration** makes privacy features accessible to all users

Combined, these features enable GDPR-compliant, air-gapped, and cost-free persona generation workflows.

---

## Related Documentation

- [v1.3.0 Milestone](../../roadmap/milestones/v1.3.0.md)
- [v1.3.0 Retrospective](../retrospectives/v1.3.0-retrospective.md)
- [F-112: Native Ollama Provider](../../roadmap/features/completed/F-112-native-ollama-provider.md)
- [F-113: PII Detection & Anonymisation](../../roadmap/features/completed/F-113-pii-detection-anonymisation.md)
- [R-013: Local Model Assessment](../../research/R-013-local-model-assessment.md)
- [Privacy Setup Guide](../../../guides/privacy-setup.md)

---

**Status**: Complete
