# DevLog: v0.9.0 - Logging & Monitoring

## Implementation Narrative

v0.9.0 introduces a comprehensive logging and monitoring system for persona generation experiments. Six focused modules enable tracking of experiments, tokens, costs, progress, and metadata - everything needed for reproducible research and cost management.

### Day 1: Module Architecture

The logging module was designed around separation of concerns. Rather than one monolithic logger, each concern gets its own file:

```
logging/
├── __init__.py           # Clean public API
├── experiment_logger.py  # F-073: Experiment events
├── structured.py         # F-074: Context-aware logging
├── progress.py           # F-075: Rich progress bars
├── metadata.py           # F-076: Reproducibility data
├── token_usage.py        # F-077: Token tracking
└── cost_tracker.py       # F-078: Budget management
```

This structure makes each feature independently testable and maintainable.

### Day 2: Experiment Logger (F-073)

The ExperimentLogger is the foundation - it captures events during persona generation with timestamps, levels, and structured data. Key design decisions:

**JSON Lines format**: One JSON object per line enables streaming reads and easy grep filtering:

```python
{"timestamp": "2025-01-01T00:00:00+00:00", "level": "info", "event": "EXPERIMENT_STARTED", ...}
{"timestamp": "2025-01-01T00:01:00+00:00", "level": "info", "event": "DATA_LOADED", ...}
```

**Enum-based event types**: Rather than arbitrary strings, `EventType` enum ensures consistency:

```python
class EventType(Enum):
    EXPERIMENT_STARTED = "EXPERIMENT_STARTED"
    DATA_LOADED = "DATA_LOADED"
    GENERATION_COMPLETED = "GENERATION_COMPLETED"
    PROVIDER_INITIALISED = "PROVIDER_INITIALISED"  # British spelling
```

**Context manager for file safety**: The `with ExperimentLogger(...) as logger:` pattern ensures files are closed even on exceptions.

### Day 3: Structured Logging (F-074)

StructuredLogger provides context propagation - bind experiment IDs once, and they appear in all subsequent logs:

```python
logger = StructuredLogger()
bound = logger.bind(experiment_id="exp-123", run_id="run-456")
bound.info("generation_started")  # experiment_id included automatically
```

The `merge()` method on LogContext enables layered contexts - parent contexts provide defaults, child contexts can override specific fields.

Output formats are configurable: JSON for machine processing, CONSOLE for human readability, BOTH for development.

### Day 4: Progress and Metadata (F-075, F-076)

Progress tracking integrates with Rich library for beautiful terminal output:

```python
with ProgressTracker(title="Generating Personas") as tracker:
    task_id = tracker.add_task("Loading data", total=100)
    for item in items:
        tracker.update(task_id, advance=1)
```

The `quiet=True` flag disables visual output for automated/headless environments - essential for CI pipelines.

MetadataRecorder captures everything needed for reproducibility:
- Environment (Python version, platform, timezone)
- Configuration (model, parameters, persona count)
- Data sources (files, tokens, checksums)
- Costs (input/output tokens, USD)
- Timing (start, end, duration)

The `calculate_checksum()` function provides SHA-256 hashes for data verification.

### Day 5: Token and Cost Tracking (F-077, F-078)

TokenUsageLogger provides detailed token breakdowns by step and component:

```python
logger.log(
    step="generation",
    model="claude-sonnet-4",
    input_tokens=10000,
    output_tokens=2000,
    breakdown=TokenBreakdown(system=1000, data=7000, instructions=2000),
)
```

The breakdown enables analysis of where tokens are spent - crucial for prompt optimisation.

CostTracker adds budget management with configurable thresholds:

```python
budget = BudgetConfig(daily=10.00, warn_threshold=0.8, block_threshold=1.0)
tracker = CostTracker(budget=budget)

if tracker.should_warn():
    print("Approaching budget limit")
if tracker.should_block():
    print("Budget exceeded - blocking further operations")
```

The caller decides how to respond to warnings/blocks - the tracker doesn't enforce behaviour, just provides information.

### Day 6: Testing

Wrote 195 unit tests across 6 test files, mirroring the source structure:

```
tests/unit/core/logging/
├── test_experiment_logger.py  # 34 tests
├── test_structured.py         # 30 tests
├── test_progress.py           # 32 tests
├── test_metadata.py           # 35 tests
├── test_token_usage.py        # 31 tests
└── test_cost_tracker.py       # 33 tests
```

Float precision was a recurring theme - `pytest.approx()` is essential for any financial calculations:

```python
assert record.variance_percent == pytest.approx(-10.0)  # Not exact float
```

## Challenges Encountered

- **Test API Alignment**: Initial tests were written against assumed APIs before reading implementation. This led to 23 failures on first run. Lesson: read the actual code before writing tests.

- **Float Precision**: Financial calculations (costs, percentages) require careful handling. Python floats can't exactly represent 0.05. Using `pytest.approx()` throughout financial tests.

- **Global Logger State**: The `get_logger()` function returns a singleton. Tests that modify global state can interfere with each other. Used fresh logger instances in tests where possible.

- **Rich Library in CI**: Progress bars need TTY detection for headless environments. The `quiet=True` parameter provides graceful degradation.

## Code Highlights

### Context Binding Pattern

```python
class StructuredLogger:
    def bind(self, **kwargs) -> "StructuredLogger":
        """Return new logger with additional context bound."""
        extra = {k: v for k, v in kwargs.items() if not hasattr(LogContext, k)}
        new_context = LogContext(
            experiment_id=kwargs.get("experiment_id", self.context.experiment_id),
            run_id=kwargs.get("run_id", self.context.run_id),
            extra={**self.context.extra, **extra},
        )
        return StructuredLogger(
            name=self.name,
            context=new_context,
            output_format=self.output_format,
        )
```

### Budget Status Check

```python
def check_budget(self) -> list[BudgetStatus]:
    """Check all budget periods and return status."""
    statuses = []
    for period in ["daily", "weekly", "monthly"]:
        limit = getattr(self.budget, period, None)
        if limit:
            spent = self._get_period_spending(period)
            percent = spent / limit if limit > 0 else 0
            status = self._determine_status(percent)
            statuses.append(BudgetStatus(period, spent, limit, percent, status))
    return statuses
```

### Metadata to Dict with Nested Structure

```python
def to_dict(self) -> dict[str, Any]:
    """Convert to dictionary for JSON serialisation."""
    return {
        "metadata_version": self.metadata_version,
        "generation": {
            "experiment_id": self.experiment_id,
            "run_id": self.run_id,
            "timestamp_start": self.timestamp_start,
            "timestamp_end": self.timestamp_end,
            "duration_seconds": self.duration_seconds,
        },
        "configuration": self.configuration.to_dict(),
        "data_sources": self.data_sources.to_dict(),
        "environment": self.environment.to_dict(),
        "costs": self.costs.to_dict(),
        "checksums": self.checksums,
        "errors": self.errors,
        "warnings": self.warnings,
    }
```

## Dependencies Added

No new dependencies required. All features implemented using:
- `dataclasses` - All data structures
- `enum` - LogLevel, EventType, OutputFormat, TaskStatus
- `json` - Serialisation
- `datetime` - Timestamps
- `hashlib` - Checksum calculation
- `pathlib` - File handling
- `rich` - Progress bars (already a project dependency)

## Summary

v0.9.0 provides comprehensive observability for persona generation. The modular architecture keeps each concern isolated while the clean public API (`from persona.core.logging import ...`) makes adoption straightforward. With 195 tests and 87% coverage, the logging system is ready for production use.

The budget management feature is particularly valuable - it enables proactive cost control for LLM operations, a common concern in AI applications.

---

## Related Documentation

- [v0.9.0 Milestone](../../roadmap/milestones/v0.9.0.md)
- [v0.9.0 Retrospective](../retrospectives/v0.9.0-retrospective.md)
- [Manual Test Script](../../../../tests/manual/v0.9.0_test_script.md)

---

**Status**: Complete
