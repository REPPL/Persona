# Retrospective: v1.5.0 - Hybrid Pipeline

## Overview

v1.5.0 completes the "Best of Both Worlds" theme with 1 feature enabling cost-optimised persona generation through hybrid local/frontier orchestration.

| Feature | Category | Status |
|---------|----------|--------|
| F-116: Hybrid Local/Frontier Pipeline | Optimisation | ✅ Complete |

## What Went Well

### Architecture & Design

- **Clean pipeline abstraction**: Five distinct stages (prepare → draft → filter → refine → output) make the flow easy to understand and test.

- **Configuration-driven behaviour**: `HybridConfig` dataclass provides clear, documented options without hidden magic.

- **Graceful degradation**: Pipeline handles missing local provider by falling back to frontier-only with clear warning.

- **Budget-first design**: Cost controls built in from the start, not bolted on afterwards.

### Implementation Quality

- **Leverages existing features**: F-114 (judge) and F-113 (PII) integrate naturally rather than duplicating functionality.

- **Accurate cost tracking**: Real cost reports after generation help users understand actual vs estimated costs.

- **Preview mode**: `--estimate-only` lets users validate costs before committing to expensive runs.

### User Experience

- **Simple defaults**: `--hybrid` flag enables sensible defaults; most users don't need to tune parameters.

- **Clear cost comparison**: Documentation shows concrete cost/quality trade-offs for different configurations.

- **Privacy mode**: `--no-frontier` provides clear path for sensitive data without complex configuration.

## What Could Be Improved

### Technical Issues

- **Quality threshold tuning**: Default 0.75 threshold works for most cases but optimal value varies by model and use case.

- **Draft multiplier trade-off**: Higher multipliers improve selection but increase local compute time significantly.

- **Refinement prompt optimisation**: Current refinement prompts are generic; domain-specific prompts could improve quality.

### Process

- **Limited real-world testing**: Cost comparisons based on synthetic benchmarks; real user data patterns may differ.

- **Model-specific tuning**: Optimal parameters vary by local model (Llama 3 vs Qwen vs Mistral) but documentation provides single recommendations.

- **Missing A/B comparison tool**: Users can't easily compare hybrid vs frontier-only output quality.

## Lessons Learned

1. **Draft quality matters**: More drafts isn't always better; quality filtering depends on having enough good candidates in the pool.

2. **Local models are capable**: 70B+ parameter models achieve 88-90% quality vs frontier, making hybrid viable.

3. **Budget controls essential**: Without caps, users can accidentally spend more on hybrid than frontier-only.

4. **Privacy mode popular**: Many users want local-only mode even at quality cost - privacy trumps quality for them.

5. **Cost estimation accuracy**: Token counting for cost estimation requires refinement context, not just persona content.

## Decisions Made

1. **Default draft multiplier = 2**: Balances quality selection with compute time; users can increase for better selection.

2. **Default threshold = 0.75**: Filters bottom 25% of drafts; high enough to improve quality, low enough to have candidates.

3. **Budget as soft cap**: Exceeding budget triggers warning and fallback, not hard failure.

4. **Frontier refinement optional**: Not forced; users can disable for privacy or further cost savings.

5. **Single pipeline class**: One `HybridPipeline` with configuration rather than separate `LocalPipeline`, `FrontierPipeline`, etc.

## Metrics

| Metric | Value |
|--------|-------|
| Features completed | 1 |
| Total tests | 2873+ |
| Tests for milestone | 73+ |
| Test coverage | >90% |
| Cost reduction achieved | 50-70% |
| Quality retention | 91-93% |

## Key Files Added

```
src/persona/
└── core/
    └── hybrid/              # Hybrid Pipeline (F-116)
        ├── __init__.py
        ├── pipeline.py      # HybridPipeline class
        ├── config.py        # HybridConfig dataclass
        └── cost.py          # Cost estimation utilities

tests/
└── unit/
    └── core/
        └── hybrid/
            ├── test_pipeline.py
            ├── test_config.py
            └── test_cost.py
```

## Commands Added

```bash
# Basic hybrid generation
persona generate --input research.csv --hybrid

# Specify models
persona generate --input data.csv --hybrid --local-model qwen2.5:72b --frontier anthropic

# Budget-constrained
persona generate --input data.csv --hybrid --max-cost 5.00

# Privacy mode (local only)
persona generate --input sensitive.csv --hybrid --no-frontier

# Cost estimation
persona generate --input data.csv --hybrid --estimate-only

# Custom configuration
persona generate --input data.csv --hybrid --draft-multiplier 3 --quality-threshold 0.85
```

## Cost Comparison Summary

| Configuration | Cost (10 personas) | Quality | Use Case |
|---------------|-------------------|---------|----------|
| Frontier Only | $2.00 | 95% | Maximum quality |
| Hybrid (default) | $1.00 | 93% | Balanced |
| Hybrid (cost-optimised) | $0.60 | 91% | Budget-conscious |
| Local Only | $0.00 | 88% | Privacy-first |

## Use Cases Enabled

| Use Case | How Addressed |
|----------|---------------|
| Budget-conscious teams | 50%+ cost reduction with minimal quality loss |
| High-volume generation | Scalable with budget caps |
| Privacy + quality | Local drafts protect input data |
| Quality assurance | Multi-stage filtering improves output |
| Cost predictability | `--estimate-only` before commit |

---

## Related Documentation

- [v1.5.0 Milestone](../../roadmap/milestones/v1.5.0.md)
- [v1.5.0 DevLog](../devlogs/v1.5.0-devlog.md)
- [F-116: Hybrid Local/Frontier Pipeline](../../roadmap/features/completed/F-116-hybrid-local-frontier-pipeline.md)
- [R-013: Local Model Assessment](../../research/R-013-local-model-assessment.md)

---

**Status**: Complete
