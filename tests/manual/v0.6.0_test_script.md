# Smoke Test: v0.6.0 - Security (5-10 minutes)

## Prerequisites

```bash
cd ~/Development/Sandboxed/Persona
source .venv/bin/activate
pip install -e ".[all]"
```

## Quick Verification

### 1. Version Check
```bash
python -c "import persona; print(persona.__version__)"
```
- [ ] Shows `0.6.0`

### 2. API Key Protection (F-051)
```bash
python -c "
from persona.core.security.keys import (
    SecureString,
    mask_api_key,
    redact_api_keys,
    KeyMaskingFilter,
)

# Test SecureString
secret = SecureString('sk-ant-api03-abc123xyz789def456')
print('SecureString str():', str(secret))  # Should show REDACTED
print('SecureString masked:', secret.get_masked())  # Should show partial

# Test mask_api_key
print('Masked key:', mask_api_key('sk-ant-api03-abc123xyz789def456'))

# Test redact_api_keys
text = 'Using key sk-ant-api03-abc123xyz789def456 for API'
print('Redacted:', redact_api_keys(text))

print('API Key Protection: OK')
"
```
- [ ] SecureString shows REDACTED in str()
- [ ] Masked key shows prefix and suffix only
- [ ] redact_api_keys hides key in text

### 3. API Key Rotation (F-052)
```bash
python -c "
from persona.core.security.rotation import KeyManager, KeyStatus

# Create key manager
manager = KeyManager()

# Add test keys (not real keys)
manager.add_key('test-provider', 'sk-test-primary-key12345678901234', is_primary=True)
manager.add_key('test-provider', 'sk-test-backup-key12345678901234', is_primary=False)

# Get current key
key = manager.get_key('test-provider')
print('Current key (masked):', manager.get_key_masked('test-provider'))

# Check key status
status = manager.get_key_status('test-provider')
print('Key status:', status)

# Test rotation
manager.mark_key_failed('test-provider', 'sk-test-primary-key12345678901234', 'Auth failed')
new_key = manager.get_key('test-provider')
print('After failure, key changed:', key != new_key)

print('API Key Rotation: OK')
"
```
- [ ] Key manager initialises
- [ ] Can add primary and backup keys
- [ ] Rotation occurs after marking key failed

### 4. Input Validation (F-053)
```bash
python -c "
from persona.core.security.validation import (
    InputValidator,
    validate_provider,
    validate_path,
)

validator = InputValidator()

# Test provider validation
result = validator.validate_provider('openai')
print('OpenAI valid:', result.valid)

result = validator.validate_provider('invalid-provider')
print('Invalid provider caught:', not result.valid)
print('Suggestions provided:', result.suggestions is not None)

# Test path validation
result = validator.validate_path('/tmp', must_exist=True, must_be_directory=True)
print('/tmp validation:', result.valid)

# Test string validation
result = validator.validate_string('test', min_length=1, max_length=10)
print('String validation:', result.valid)

# Test URL validation
result = validator.validate_url('https://api.openai.com')
print('URL validation:', result.valid)

print('Input Validation: OK')
"
```
- [ ] Valid providers pass validation
- [ ] Invalid providers are rejected with suggestions
- [ ] Path validation works
- [ ] URL validation requires HTTPS

### 5. Security Scanning (F-054)
```bash
# Check pre-commit config exists
cat .pre-commit-config.yaml | head -20
```
- [ ] Pre-commit config exists
- [ ] Contains bandit hook
- [ ] Contains detect-secrets hook

```bash
# Check secrets baseline exists
cat .secrets.baseline | head -10
```
- [ ] Secrets baseline file exists

### 6. Configuration Validation (F-055)
```bash
python -c "
from persona.core.config.validator import ConfigValidator, validate_config

validator = ConfigValidator()

# Test valid experiment config
result = validator.validate_data({
    'name': 'test-experiment',
    'provider': 'openai',
    'model': 'gpt-4o',
    'count': 3,
}, config_type='experiment')
print('Valid experiment config:', result.is_valid)

# Test invalid experiment config (bad provider)
result = validator.validate_data({
    'name': 'test',
    'provider': 'invalid-provider',
}, config_type='experiment')
print('Invalid provider caught:', not result.is_valid)
print('Errors:', [str(e) for e in result.errors])

# Test invalid experiment name
result = validator.validate_data({
    'name': 'invalid name with spaces!',
}, config_type='experiment')
print('Invalid name caught:', not result.is_valid)

# Test valid vendor config
result = validator.validate_data({
    'name': 'Custom Provider',
    'api_base': 'https://api.example.com',
    'auth_env': 'CUSTOM_API_KEY',
}, config_type='vendor')
print('Valid vendor config:', result.is_valid)

print('Configuration Validation: OK')
"
```
- [ ] Valid configs pass validation
- [ ] Invalid provider rejected
- [ ] Invalid name pattern rejected
- [ ] HTTPS required for vendor API base

### 7. Model Availability Checking (F-056)
```bash
python -c "
from persona.core.discovery.checker import (
    ModelChecker,
    check_model,
    warn_if_deprecated,
    DEPRECATED_MODELS,
)

checker = ModelChecker()

# Check deprecated model
result = checker.check('claude-2.0', 'anthropic')
print('claude-2.0 deprecated:', result.is_deprecated)
print('Replacement:', result.replacement)

# Check current model
result = checker.check('gpt-4o', 'openai')
print('gpt-4o status:', result.status.value)

# Get alternatives
alternatives = checker.get_alternatives('claude-2.0', 'anthropic')
print('Alternatives count:', len(alternatives))

# Get deprecation warning
warning = warn_if_deprecated('claude-2.0', 'anthropic')
print('Warning generated:', warning is not None)

# Suggest model for provider
suggestion = checker.suggest_model('anthropic')
print('Anthropic suggestion:', suggestion)

print('Model Availability Checking: OK')
"
```
- [ ] Deprecated models identified
- [ ] Replacements suggested
- [ ] Alternatives provided
- [ ] Model suggestions work

### 8. Rate Limiting (F-057)
```bash
python -c "
import asyncio
from persona.core.security.rate_limiter import (
    RateLimiter,
    SyncRateLimiter,
    RateLimitConfig,
    DEFAULT_RATE_LIMITS,
)

# Check default rate limits exist
print('Anthropic limits:', 'anthropic' in DEFAULT_RATE_LIMITS)
print('OpenAI limits:', 'openai' in DEFAULT_RATE_LIMITS)
print('Gemini limits:', 'gemini' in DEFAULT_RATE_LIMITS)

# Test sync rate limiter
limiter = SyncRateLimiter()
wait_time = limiter.acquire('anthropic')
print('Acquired token, wait time:', wait_time)

status = limiter.get_status('anthropic')
print('Status keys:', list(status.keys()))

# Test async rate limiter
async def test_async():
    limiter = RateLimiter()
    wait_time = await limiter.acquire('openai')
    print('Async acquire wait time:', wait_time)
    limiter.release('openai')
    return True

asyncio.run(test_async())

print('Rate Limiting: OK')
"
```
- [ ] Default rate limits for all providers
- [ ] Sync rate limiter works
- [ ] Async rate limiter works
- [ ] Status tracking works

### 9. Error Handling & Retry (F-058)
```bash
python -c "
import asyncio
from persona.core.security.retry import (
    ErrorClassifier,
    RetryStrategy,
    CircuitBreaker,
    CircuitBreakerConfig,
    RetryExecutor,
    ErrorType,
)

classifier = ErrorClassifier()

# Test error classification
print('429 -> Rate limit:', classifier.classify_status_code(429) == ErrorType.RATE_LIMIT)
print('401 -> Auth failure:', classifier.classify_status_code(401) == ErrorType.AUTH_FAILURE)
print('500 -> Server error:', classifier.classify_status_code(500) == ErrorType.SERVER_ERROR)

# Test retryability
print('Rate limit retryable:', classifier.is_retryable(ErrorType.RATE_LIMIT))
print('Auth failure not retryable:', not classifier.is_retryable(ErrorType.AUTH_FAILURE))

# Test retry strategy
strategy = RetryStrategy(max_retries=3, initial_delay=1.0, jitter=False)
delay = strategy.calculate_delay(0)
print('Initial delay:', delay)
delay = strategy.calculate_delay(2)
print('Exponential delay (attempt 2):', delay)

# Test circuit breaker
breaker = CircuitBreaker('test')
print('Initial state closed:', breaker.is_closed)
breaker.record_success()
print('After success still closed:', breaker.is_closed)

# Test executor
executor = RetryExecutor()
call_count = 0
def success_op():
    global call_count
    call_count += 1
    return 'success'

result = executor.execute_sync(success_op)
print('Executor result:', result)
print('Call count:', call_count)

print('Error Handling & Retry: OK')
"
```
- [ ] Error classification works correctly
- [ ] Retryability determined correctly
- [ ] Retry strategy calculates delays
- [ ] Circuit breaker tracks state
- [ ] Executor runs operations

### 10. All Tests Pass
```bash
pytest tests/ -q
```
- [ ] All 1711 tests pass

### 11. Cleanup
```bash
# No cleanup needed for this version
echo "No cleanup required"
```

## Report

- **Version**: v0.6.0
- **Date**: ___
- **Result**: PASS / FAIL
- **Notes**: ___
