# Manual Test Script: v0.6.0 - Security

This script verifies all v0.6.0 functionality. Execute tests in order and record results.

## Prerequisites

- Python 3.12+
- Git checkout of v0.6.0 tag
- No API keys required (tests use mock responses)

## Installation

```bash
# 1. Checkout the version
git checkout v0.6.0

# 2. Create fresh virtual environment
python3.12 -m venv .venv-test
source .venv-test/bin/activate  # On Windows: .venv-test\Scripts\activate

# 3. Install Persona with all dependencies
pip install -e ".[all]"

# 4. Verify installation
python -c "import persona; print(f'Persona v{persona.__version__}')"
```

**Expected:** Shows Persona v0.6.0

---

## Test 1: Version Check

**Command:**
```bash
python -c "import persona; print(persona.__version__)"
```

**Expected:** Shows 0.6.0

**Pass Criteria:**
- [ ] Shows 0.6.0

---

## Test 2: API Key Protection (F-051)

**Command:**
```bash
python -c "
from persona.core.security.keys import (
    SecureString,
    mask_api_key,
    redact_api_keys,
    KeyMaskingFilter,
)

# Test SecureString
secret = SecureString('sk-ant-api03-abc123xyz789def456')
print('SecureString str():', str(secret))  # Should show REDACTED
print('SecureString masked:', secret.get_masked())  # Should show partial

# Test mask_api_key
print('Masked key:', mask_api_key('sk-ant-api03-abc123xyz789def456'))

# Test redact_api_keys
text = 'Using key sk-ant-api03-abc123xyz789def456 for API'
print('Redacted:', redact_api_keys(text))

print('API Key Protection: OK')
"
```

**Expected:** SecureString shows REDACTED in str(), masked key shows prefix and suffix only, redact_api_keys hides key in text, then "API Key Protection: OK"

**Pass Criteria:**
- [ ] SecureString shows REDACTED in str()
- [ ] Masked key shows prefix and suffix only
- [ ] redact_api_keys hides key in text

---

## Test 3: API Key Rotation (F-052)

**Command:**
```bash
python -c "
from persona.core.security.rotation import KeyManager, KeyStatus
from persona.core.security.keys import mask_api_key

# Create key manager
manager = KeyManager()

# Register test provider with keys (not real keys)
manager.register_provider(
    'test-provider',
    keys=['sk-test-primary-key12345678901234', 'sk-test-backup-key12345678901234'],
)

# Get current key
key = manager.get_key('test-provider')
print('Current key (masked):', mask_api_key(key.get_value()) if key else 'None')

# Check key health
health = manager.get_health('test-provider')
print('Keys configured:', len(health))
print('First key healthy:', health[0].is_healthy if health else False)

# Test rotation by marking key as failed
if key:
    manager.mark_failure('test-provider', key, 'Auth failed', is_auth_failure=True)
    new_key = manager.get_key('test-provider')
    # After auth failure, should rotate to backup key
    print('Key changed after failure:', key.get_value() != (new_key.get_value() if new_key else ''))

print('API Key Rotation: OK')
"
```

**Expected:** Key manager initialises, can register provider with multiple keys, rotation occurs after marking key failed, then "API Key Rotation: OK"

**Pass Criteria:**
- [ ] Key manager initialises
- [ ] Can register provider with multiple keys
- [ ] Rotation occurs after marking key failed

---

## Test 4: Input Validation (F-053)

**Command:**
```bash
python -c "
from persona.core.security.validation import (
    InputValidator,
    validate_provider,
    validate_path,
)

validator = InputValidator()

# Test provider validation
result = validator.validate_provider('openai')
print('OpenAI valid:', result.valid)

result = validator.validate_provider('invalid-provider')
print('Invalid provider caught:', not result.valid)
print('Suggestions provided:', result.suggestions is not None)

# Test path validation
result = validator.validate_path('/tmp', must_exist=True, must_be_directory=True)
print('/tmp validation:', result.valid)

# Test string validation
result = validator.validate_string('test', min_length=1, max_length=10)
print('String validation:', result.valid)

# Test URL validation
result = validator.validate_url('https://api.openai.com')
print('URL validation:', result.valid)

print('Input Validation: OK')
"
```

**Expected:** Valid providers pass validation, invalid providers are rejected with suggestions, path validation works, URL validation requires HTTPS, then "Input Validation: OK"

**Pass Criteria:**
- [ ] Valid providers pass validation
- [ ] Invalid providers are rejected with suggestions
- [ ] Path validation works
- [ ] URL validation requires HTTPS

---

## Test 5: Security Scanning (F-054)

**Command:**
```bash
cat .pre-commit-config.yaml | head -20
```

**Expected:** Pre-commit config exists, contains bandit hook, contains detect-secrets hook

**Pass Criteria:**
- [ ] Pre-commit config exists
- [ ] Contains bandit hook
- [ ] Contains detect-secrets hook

**Command:**
```bash
cat .secrets.baseline | head -10
```

**Expected:** Secrets baseline file exists

**Pass Criteria:**
- [ ] Secrets baseline file exists

---

## Test 6: Configuration Validation (F-055)

**Command:**
```bash
python -c "
from persona.core.config.validator import ConfigValidator, validate_config

validator = ConfigValidator()

# Test valid experiment config
result = validator.validate_data({
    'name': 'test-experiment',
    'provider': 'openai',
    'model': 'gpt-4o',
    'count': 3,
}, config_type='experiment')
print('Valid experiment config:', result.is_valid)

# Test invalid experiment config (bad provider)
result = validator.validate_data({
    'name': 'test',
    'provider': 'invalid-provider',
}, config_type='experiment')
print('Invalid provider caught:', not result.is_valid)
print('Errors:', [str(e) for e in result.errors])

# Test invalid experiment name
result = validator.validate_data({
    'name': 'invalid name with spaces!',
}, config_type='experiment')
print('Invalid name caught:', not result.is_valid)

# Test valid vendor config
result = validator.validate_data({
    'name': 'Custom Provider',
    'api_base': 'https://api.example.com',
    'auth_env': 'CUSTOM_API_KEY',
}, config_type='vendor')
print('Valid vendor config:', result.is_valid)

print('Configuration Validation: OK')
"
```

**Expected:** Valid configs pass validation, invalid provider rejected, invalid name pattern rejected, HTTPS required for vendor API base, then "Configuration Validation: OK"

**Pass Criteria:**
- [ ] Valid configs pass validation
- [ ] Invalid provider rejected
- [ ] Invalid name pattern rejected
- [ ] HTTPS required for vendor API base

---

## Test 7: Model Availability Checking (F-056)

**Command:**
```bash
python -c "
from persona.core.discovery.checker import (
    ModelChecker,
    check_model,
    warn_if_deprecated,
    DEPRECATED_MODELS,
)

checker = ModelChecker()

# Check deprecated model
result = checker.check('claude-2.0', 'anthropic')
print('claude-2.0 deprecated:', result.is_deprecated)
print('Replacement:', result.replacement)

# Check current model
result = checker.check('gpt-4o', 'openai')
print('gpt-4o status:', result.status.value)

# Get alternatives
alternatives = checker.get_alternatives('claude-2.0', 'anthropic')
print('Alternatives count:', len(alternatives))

# Get deprecation warning
warning = warn_if_deprecated('claude-2.0', 'anthropic')
print('Warning generated:', warning is not None)

# Suggest model for provider
suggestion = checker.suggest_model('anthropic')
print('Anthropic suggestion:', suggestion)

print('Model Availability Checking: OK')
"
```

**Expected:** Deprecated models identified, replacements suggested, alternatives provided, model suggestions work, then "Model Availability Checking: OK"

**Pass Criteria:**
- [ ] Deprecated models identified
- [ ] Replacements suggested
- [ ] Alternatives provided
- [ ] Model suggestions work

---

## Test 8: Rate Limiting (F-057)

**Command:**
```bash
python -c "
import asyncio
from persona.core.security.rate_limiter import (
    RateLimiter,
    SyncRateLimiter,
    RateLimitConfig,
    DEFAULT_RATE_LIMITS,
)

# Check default rate limits exist
print('Anthropic limits:', 'anthropic' in DEFAULT_RATE_LIMITS)
print('OpenAI limits:', 'openai' in DEFAULT_RATE_LIMITS)
print('Gemini limits:', 'gemini' in DEFAULT_RATE_LIMITS)

# Test sync rate limiter
limiter = SyncRateLimiter()
wait_time = limiter.acquire('anthropic')
print('Acquired token, wait time:', wait_time)

status = limiter.get_status('anthropic')
print('Status keys:', list(status.keys()))

# Test async rate limiter
async def test_async():
    limiter = RateLimiter()
    wait_time = await limiter.acquire('openai')
    print('Async acquire wait time:', wait_time)
    limiter.release('openai')
    return True

asyncio.run(test_async())

print('Rate Limiting: OK')
"
```

**Expected:** Default rate limits for all providers, sync rate limiter works, async rate limiter works, status tracking works, then "Rate Limiting: OK"

**Pass Criteria:**
- [ ] Default rate limits for all providers
- [ ] Sync rate limiter works
- [ ] Async rate limiter works
- [ ] Status tracking works

---

## Test 9: Error Handling & Retry (F-058)

**Command:**
```bash
python -c "
import asyncio
from persona.core.security.retry import (
    ErrorClassifier,
    RetryStrategy,
    CircuitBreaker,
    CircuitBreakerConfig,
    RetryExecutor,
    ErrorType,
)

classifier = ErrorClassifier()

# Test error classification
print('429 -> Rate limit:', classifier.classify_status_code(429) == ErrorType.RATE_LIMIT)
print('401 -> Auth failure:', classifier.classify_status_code(401) == ErrorType.AUTH_FAILURE)
print('500 -> Server error:', classifier.classify_status_code(500) == ErrorType.SERVER_ERROR)

# Test retryability
print('Rate limit retryable:', classifier.is_retryable(ErrorType.RATE_LIMIT))
print('Auth failure not retryable:', not classifier.is_retryable(ErrorType.AUTH_FAILURE))

# Test retry strategy
strategy = RetryStrategy(max_retries=3, initial_delay=1.0, jitter=False)
delay = strategy.calculate_delay(0)
print('Initial delay:', delay)
delay = strategy.calculate_delay(2)
print('Exponential delay (attempt 2):', delay)

# Test circuit breaker
breaker = CircuitBreaker('test')
print('Initial state closed:', breaker.is_closed)
breaker.record_success()
print('After success still closed:', breaker.is_closed)

# Test executor
executor = RetryExecutor()
call_count = 0
def success_op():
    global call_count
    call_count += 1
    return 'success'

result = executor.execute_sync(success_op)
print('Executor result:', result)
print('Call count:', call_count)

print('Error Handling & Retry: OK')
"
```

**Expected:** Error classification works correctly, retryability determined correctly, retry strategy calculates delays, circuit breaker tracks state, executor runs operations, then "Error Handling & Retry: OK"

**Pass Criteria:**
- [ ] Error classification works correctly
- [ ] Retryability determined correctly
- [ ] Retry strategy calculates delays
- [ ] Circuit breaker tracks state
- [ ] Executor runs operations

---

## Test 10: Run Automated Tests

**Command:**
```bash
pytest tests/ -q
```

**Expected:** All 1711 tests pass

**Pass Criteria:**
- [ ] All tests pass

---

## Results Summary

| Test | Status | Notes |
|------|--------|-------|
| 1. Version Check | ⬜ | |
| 2. API Key Protection | ⬜ | |
| 3. API Key Rotation | ⬜ | |
| 4. Input Validation | ⬜ | |
| 5. Security Scanning | ⬜ | |
| 6. Configuration Validation | ⬜ | |
| 7. Model Availability Checking | ⬜ | |
| 8. Rate Limiting | ⬜ | |
| 9. Error Handling & Retry | ⬜ | |
| 10. Automated Tests | ⬜ | |

**Overall Result:** ⬜ Pass / ⬜ Fail

---

## Sharing Results

After completing all tests, share:

1. The completed results table above
2. Console output from any failed tests
3. Your environment details:
   - OS:
   - Python version:
   - Any issues encountered

Paste results to Claude for review.
