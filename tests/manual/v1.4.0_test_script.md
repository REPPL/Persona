# Manual Test Script: v1.4.0 - Quality & Data Generation

## Prerequisites

### For Evaluation Tests (F-114)
- [ ] Ollama installed and running (`ollama serve`)
- [ ] At least one model available (`ollama list`)
- [ ] Test personas available

### For Synthetic Data Tests (F-115)
- [ ] Privacy extras installed (`pip install persona[privacy]`)
- [ ] Test CSV/JSON data files available

---

## F-114: LLM-as-Judge Persona Evaluation

### Test 1: Basic Evaluation
```bash
# Create test persona
cat > /tmp/test_persona.json << 'EOF'
{
  "name": "Alex Chen",
  "age": 34,
  "occupation": "Software Engineer",
  "goals": ["Build efficient systems", "Learn new technologies"],
  "frustrations": ["Slow build times", "Unclear documentation"],
  "background": "Alex has 10 years of experience in backend development."
}
EOF

persona evaluate /tmp/test_persona.json --judge ollama
```
- [ ] Evaluation completes without errors
- [ ] Shows scores for coherence, realism, usefulness
- [ ] Scores are between 0.0 and 1.0
- [ ] Overall score displayed

### Test 2: Specify Model
```bash
persona evaluate /tmp/test_persona.json --judge ollama --model llama3.2:3b
```
- [ ] Uses specified model
- [ ] Evaluation completes successfully

### Test 3: Select Criteria
```bash
persona evaluate /tmp/test_persona.json --judge ollama --criteria coherence,realism
```
- [ ] Only shows coherence and realism scores
- [ ] Usefulness and distinctiveness not shown

### Test 4: Batch Evaluation with Distinctiveness
```bash
# Create multiple personas
cat > /tmp/personas_batch.json << 'EOF'
[
  {"name": "Alex Chen", "occupation": "Software Engineer", "goals": ["Build efficient systems"]},
  {"name": "Maria Garcia", "occupation": "UX Designer", "goals": ["Create intuitive interfaces"]},
  {"name": "James Wilson", "occupation": "Product Manager", "goals": ["Ship products on time"]}
]
EOF

persona evaluate /tmp/personas_batch.json --judge ollama --criteria coherence,distinctiveness
```
- [ ] All three personas evaluated
- [ ] Distinctiveness scores compare across batch
- [ ] Different personas have different distinctiveness scores

### Test 5: JSON Output
```bash
persona evaluate /tmp/test_persona.json --judge ollama --json
```
- [ ] Valid JSON output
- [ ] Contains all score fields
- [ ] Machine-parseable

### Test 6: Verbose Output
```bash
persona evaluate /tmp/test_persona.json --judge ollama --verbose
```
- [ ] Shows detailed reasoning for each criterion
- [ ] Explains score justification

### Test 7: Compare to Frontier (Optional - requires API key)
```bash
persona evaluate /tmp/test_persona.json --judge ollama --compare anthropic
```
- [ ] Shows local and frontier scores side by side
- [ ] Comparison summary displayed
- [ ] Graceful handling if API key not set

### Test 8: Invalid Criteria
```bash
persona evaluate /tmp/test_persona.json --judge ollama --criteria invalid_criterion
```
- [ ] Clear error message
- [ ] Lists valid criteria options

---

## F-115: Synthetic Data Generation Pipeline

### Test 9: Preview Synthetic Data
```bash
# Create test source data
cat > /tmp/source_data.csv << 'EOF'
name,age,feedback
John Smith,28,"Love the new features"
Sarah Jones,35,"Interface could be simpler"
Mike Brown,42,"Performance is excellent"
EOF

persona synthesise preview --input /tmp/source_data.csv --count 3
```
- [ ] Shows preview of 3 synthetic records
- [ ] No file created (dry run)
- [ ] Schema matches source

### Test 10: Generate Synthetic Data
```bash
persona synthesise --input /tmp/source_data.csv --output /tmp/synthetic.csv --count 5
```
- [ ] Output file created
- [ ] Contains 5 records
- [ ] Column names match source
- [ ] Data types preserved

### Test 11: Specify Model
```bash
persona synthesise --input /tmp/source_data.csv --output /tmp/synthetic2.csv --count 3 --model llama3.2:3b
```
- [ ] Uses specified model
- [ ] Generation completes successfully

### Test 12: Validate Synthetic Data
```bash
persona synthesise validate --original /tmp/source_data.csv --synthetic /tmp/synthetic.csv
```
- [ ] Shows schema match result
- [ ] Shows distribution similarity score
- [ ] Shows PII detection result (should be none)
- [ ] Shows semantic similarity score

### Test 13: Synthetic Data Has No PII
```bash
# Create source with PII
cat > /tmp/source_pii.csv << 'EOF'
name,email,feedback
John Smith,john@example.com,"Great product"
Sarah Jones,sarah@test.org,"Needs improvement"
EOF

persona synthesise --input /tmp/source_pii.csv --output /tmp/synthetic_safe.csv --count 5

# Verify no PII in output
persona privacy scan --input /tmp/synthetic_safe.csv
```
- [ ] Synthetic data generated
- [ ] Privacy scan shows no PII detected
- [ ] Names and emails are synthetic/fake

### Test 14: Large Dataset
```bash
# Create larger source (50 records)
for i in {1..50}; do
  echo "User$i,$((20 + RANDOM % 40)),\"Feedback line $i\""
done > /tmp/large_source.csv
echo "name,age,feedback" | cat - /tmp/large_source.csv > /tmp/temp && mv /tmp/temp /tmp/large_source.csv

persona synthesise --input /tmp/large_source.csv --output /tmp/large_synthetic.csv --count 100
```
- [ ] Handles larger dataset
- [ ] Progress displayed during generation
- [ ] Output has 100 records

### Test 15: JSON Input/Output
```bash
cat > /tmp/source_data.json << 'EOF'
[
  {"name": "Alice", "role": "Developer", "years": 5},
  {"name": "Bob", "role": "Designer", "years": 3}
]
EOF

persona synthesise --input /tmp/source_data.json --output /tmp/synthetic.json --count 5
```
- [ ] Handles JSON input
- [ ] Creates JSON output
- [ ] Structure preserved

### Test 16: Distribution Preservation
```bash
# Source with clear age distribution (mostly 25-35)
cat > /tmp/age_dist.csv << 'EOF'
name,age,department
A,28,Engineering
B,30,Engineering
C,32,Design
D,29,Engineering
E,31,Design
EOF

persona synthesise --input /tmp/age_dist.csv --output /tmp/age_synthetic.csv --count 20
persona synthesise validate --original /tmp/age_dist.csv --synthetic /tmp/age_synthetic.csv
```
- [ ] Distribution similarity > 0.85
- [ ] Age range similar to source
- [ ] Department ratio preserved

---

## Integration Tests

### Test 17: Evaluate Then Synthesise Workflow
```bash
# Generate personas, evaluate them, then create synthetic training data
cat > /tmp/research_data.txt << 'EOF'
User interviews from product research.
Users want faster loading times.
Mobile experience is frustrating.
Documentation is hard to find.
EOF

# Generate personas
persona generate --input /tmp/research_data.txt --provider ollama --count 2 --output /tmp/generated_personas.json

# Evaluate generated personas
persona evaluate /tmp/generated_personas.json --judge ollama

# Create synthetic version of research data
persona synthesise --input /tmp/research_data.txt --output /tmp/synthetic_research.txt --count 10
```
- [ ] Generation succeeds
- [ ] Evaluation shows quality scores
- [ ] Synthetic data created

### Test 18: Quality Gate Workflow
```bash
# Evaluate and check if passes quality threshold
persona evaluate /tmp/test_persona.json --judge ollama --threshold 0.7
echo "Exit code: $?"
```
- [ ] Exit code 0 if score >= 0.7
- [ ] Exit code 1 if score < 0.7
- [ ] Clear pass/fail message

---

## Error Handling

### Test 19: Invalid Input File
```bash
persona synthesise --input /nonexistent/file.csv --output /tmp/out.csv
```
- [ ] Clear error about file not found
- [ ] No stack trace

### Test 20: Empty Source File
```bash
echo "" > /tmp/empty.csv
persona synthesise --input /tmp/empty.csv --output /tmp/out.csv --count 5
```
- [ ] Clear error about empty source
- [ ] Helpful message

### Test 21: Help Commands
```bash
persona evaluate --help
persona synthesise --help
persona synthesise validate --help
persona synthesise preview --help
```
- [ ] All help text displays correctly
- [ ] Options documented
- [ ] Examples provided

---

## Cleanup

```bash
rm -f /tmp/test_persona.json /tmp/personas_batch.json
rm -f /tmp/source_data.csv /tmp/synthetic.csv /tmp/synthetic2.csv
rm -f /tmp/source_pii.csv /tmp/synthetic_safe.csv
rm -f /tmp/large_source.csv /tmp/large_synthetic.csv
rm -f /tmp/source_data.json /tmp/synthetic.json
rm -f /tmp/age_dist.csv /tmp/age_synthetic.csv
rm -f /tmp/research_data.txt /tmp/generated_personas.json /tmp/synthetic_research.txt
rm -f /tmp/empty.csv
```

---

## Test Results Summary

| Test | Pass | Fail | Notes |
|------|------|------|-------|
| 1. Basic Evaluation | | | |
| 2. Specify Model | | | |
| 3. Select Criteria | | | |
| 4. Batch Distinctiveness | | | |
| 5. JSON Output | | | |
| 6. Verbose Output | | | |
| 7. Compare Frontier | | | |
| 8. Invalid Criteria | | | |
| 9. Preview Synthetic | | | |
| 10. Generate Synthetic | | | |
| 11. Specify Model | | | |
| 12. Validate Synthetic | | | |
| 13. No PII in Output | | | |
| 14. Large Dataset | | | |
| 15. JSON I/O | | | |
| 16. Distribution | | | |
| 17. Evaluate+Synthesise | | | |
| 18. Quality Gate | | | |
| 19. Invalid Input | | | |
| 20. Empty Source | | | |
| 21. Help Commands | | | |

**Tester:** _______________
**Date:** _______________
**Version:** v1.4.0
**Platform:** _______________
