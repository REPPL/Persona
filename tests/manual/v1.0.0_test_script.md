# Manual Test Script: v1.0.0 - Production Ready

This script verifies all v1.0.0 functionality. Execute tests in order and record results.

## Prerequisites

- Python 3.12+
- Git checkout of v1.0.0 tag
- No API keys required (tests use mock responses where possible)

## Installation

```bash
# 1. Checkout the version
git checkout v1.0.0

# 2. Create fresh virtual environment
python3.12 -m venv .venv-test
source .venv-test/bin/activate  # On Windows: .venv-test\Scripts\activate

# 3. Install Persona with all dependencies
pip install -e ".[all]"

# 4. Verify installation
python -c "import persona; print(f'Persona v{persona.__version__}')"
```

**Expected:** Shows Persona v1.0.0

---

## Test 1: Platform Independence (F-079)

**Command:**
```bash
python -c "
from persona.core.platform import IS_WINDOWS, IS_MACOS, IS_LINUX, get_platform_name
import platform

detected = get_platform_name()
actual = platform.system().lower()

print(f'Detected platform: {detected}')
print(f'IS_WINDOWS: {IS_WINDOWS}')
print(f'IS_MACOS: {IS_MACOS}')
print(f'IS_LINUX: {IS_LINUX}')

# Verify exactly one is True
platforms = [IS_WINDOWS, IS_MACOS, IS_LINUX]
assert sum(platforms) == 1, 'Exactly one platform flag should be True'

print('Platform independence: OK')
"
```

**Expected:** Shows detected platform, exactly one platform flag is True

**Pass Criteria:**
- [ ] Platform detected correctly
- [ ] Exactly one IS_* flag is True
- [ ] No import errors

---

## Test 2: Wrapper Scripts (F-080)

**Command (Unix/macOS):**
```bash
# Check wrapper script exists and is executable
ls -la bin/persona
head -5 bin/persona
```

**Command (Windows):**
```cmd
dir bin\persona.cmd
type bin\persona.cmd | more
```

**Expected:** Wrapper scripts exist with correct shebang/batch syntax

**Pass Criteria:**
- [ ] Unix wrapper exists at bin/persona
- [ ] Windows wrapper exists at bin/persona.cmd
- [ ] Scripts have correct syntax for their platform

---

## Test 3: Path Manager (F-081)

**Command:**
```bash
python -c "
from persona.core.platform import PathManager

pm = PathManager()

# Get standard paths
config_dir = pm.get_config_dir()
data_dir = pm.get_data_dir()
cache_dir = pm.get_cache_dir()

print(f'Config directory: {config_dir}')
print(f'Data directory: {data_dir}')
print(f'Cache directory: {cache_dir}')

# Verify paths are absolute
assert config_dir.is_absolute(), 'Config path should be absolute'
assert data_dir.is_absolute(), 'Data path should be absolute'
assert cache_dir.is_absolute(), 'Cache path should be absolute'

# Test path normalisation
normalized = pm.normalize_path('~/test/path')
print(f'Normalized path: {normalized}')
assert '~' not in str(normalized), 'Tilde should be expanded'

print('PathManager: OK')
"
```

**Expected:** Shows platform-appropriate paths, all paths are absolute

**Pass Criteria:**
- [ ] PathManager creates successfully
- [ ] Paths are platform-appropriate
- [ ] Path normalisation works
- [ ] Tilde expansion works

---

## Test 4: Built-in Help System (F-082)

**Command:**
```bash
# Test main help
persona --help

# Test command-specific help
persona generate --help

# Test config help
persona config --help
```

**Expected:** Comprehensive help text with examples for each command

**Pass Criteria:**
- [ ] Main help shows all commands
- [ ] Command help shows all options
- [ ] Examples are included
- [ ] Help text is readable

---

## Test 5: Documentation Generation (F-083)

**Command:**
```bash
python -c "
from pathlib import Path

# Check documentation structure exists
docs_dir = Path('docs')
assert docs_dir.exists(), 'docs/ directory should exist'

# Check key documentation files
required_files = [
    'docs/README.md',
    'docs/tutorials/sdk-quickstart.md',
    'docs/guides/sdk-patterns.md',
    'docs/reference/api.md',
]

for file_path in required_files:
    path = Path(file_path)
    assert path.exists(), f'Missing: {file_path}'
    print(f'Found: {file_path}')

print('Documentation structure: OK')
"
```

**Expected:** All required documentation files exist

**Pass Criteria:**
- [ ] docs/ directory exists
- [ ] Tutorial files present
- [ ] Guide files present
- [ ] Reference files present

---

## Test 6: Synthetic Test Data (F-084)

**Command:**
```bash
python -c "
from pathlib import Path

# Check synthetic data directory
data_dir = Path('data/synthetic')
assert data_dir.exists(), 'data/synthetic/ should exist'

# Check interviews
interviews = list((data_dir / 'interviews').glob('*.md'))
print(f'Interview files: {len(interviews)}')
assert len(interviews) >= 5, 'Should have at least 5 interview files'

# Check surveys
surveys = list((data_dir / 'surveys').glob('*'))
print(f'Survey files: {len(surveys)}')
assert len(surveys) >= 2, 'Should have at least 2 survey files'

# Check mixed data
mixed = list((data_dir / 'mixed').glob('*'))
print(f'Mixed data files: {len(mixed)}')
assert len(mixed) >= 2, 'Should have at least 2 mixed data files'

print('Synthetic test data: OK')
"
```

**Expected:** Shows 5+ interviews, 2+ surveys, 2+ mixed files

**Pass Criteria:**
- [ ] Synthetic data directory exists
- [ ] Interview files present
- [ ] Survey files present
- [ ] Mixed data files present

---

## Test 7: Global Configuration (F-085)

**Command:**
```bash
python -c "
from persona.core.config.global_config import get_config_manager, GlobalConfig

# Get config manager
manager = get_config_manager()

# Load configuration
config = manager.load()

print(f'Default provider: {config.defaults.provider}')
print(f'Default count: {config.defaults.count}')
print(f'Default complexity: {config.defaults.complexity}')
print(f'Output format: {config.output.format}')
print(f'Logging level: {config.logging.level}')

# Verify config is GlobalConfig instance
assert isinstance(config, GlobalConfig), 'Config should be GlobalConfig'

print('Global configuration: OK')
"
```

**Expected:** Shows default configuration values

**Pass Criteria:**
- [ ] Config manager loads successfully
- [ ] Default values are sensible
- [ ] All config sections accessible

---

## Test 8: SDK Documentation (F-091)

**Command:**
```bash
python -c "
from persona import (
    PersonaGenerator,
    AsyncPersonaGenerator,
    PersonaConfig,
    PersonaModel,
    GenerationResultModel,
    PersonaError,
    ConfigurationError,
    ProviderError,
    ValidationError,
)

print('SDK imports successful:')
print(f'  PersonaGenerator: {PersonaGenerator}')
print(f'  AsyncPersonaGenerator: {AsyncPersonaGenerator}')
print(f'  PersonaConfig: {PersonaConfig}')
print(f'  PersonaModel: {PersonaModel}')
print(f'  GenerationResultModel: {GenerationResultModel}')

# Check exception hierarchy
assert issubclass(ConfigurationError, PersonaError)
assert issubclass(ProviderError, PersonaError)
assert issubclass(ValidationError, PersonaError)
print('  Exception hierarchy: correct')

print('SDK documentation imports: OK')
"
```

**Expected:** All SDK classes import successfully

**Pass Criteria:**
- [ ] All main SDK classes importable
- [ ] Exception hierarchy correct
- [ ] No import errors

---

## Test 9: Interactive Mode (F-092)

**Command:**
```bash
python -c "
from persona.ui.interactive import (
    is_interactive_supported,
    InteractivePrompts,
    GenerateWizard,
    ConfigWizard,
    ConfigEditor,
)

print('Interactive mode imports:')
print(f'  is_interactive_supported: {is_interactive_supported}')
print(f'  InteractivePrompts: {InteractivePrompts}')
print(f'  GenerateWizard: {GenerateWizard}')
print(f'  ConfigWizard: {ConfigWizard}')
print(f'  ConfigEditor: {ConfigEditor}')

# Check TTY detection
tty_supported = is_interactive_supported()
print(f'  Current TTY support: {tty_supported}')

print('Interactive mode: OK')
"
```

**Expected:** All interactive classes import successfully

**Pass Criteria:**
- [ ] Interactive mode classes importable
- [ ] TTY detection works
- [ ] No import errors

---

## Test 10: TUI Configuration Editor (F-093)

**Command:**
```bash
python -c "
from persona.ui.interactive import ConfigEditor

# Create editor instance
editor = ConfigEditor()

print(f'ConfigEditor created successfully')
print(f'  project_level: {editor.project_level}')
print(f'  prompts: {editor.prompts}')

# Test reset values
reset_values = editor._reset_all()
print(f'  Reset values count: {len(reset_values)}')
assert 'defaults.provider' in reset_values
assert 'budgets.per_run' in reset_values
assert 'output.format' in reset_values
assert 'logging.level' in reset_values

print('TUI Configuration Editor: OK')
"
```

**Expected:** ConfigEditor creates successfully, reset values are complete

**Pass Criteria:**
- [ ] ConfigEditor creates successfully
- [ ] Reset values include all sections
- [ ] No initialization errors

---

## Test 11: Streaming Output Display (F-094)

**Command:**
```bash
python -c "
from persona.ui.streaming import (
    StreamingOutput,
    SimpleProgress,
    GenerationProgress,
    PersonaProgress,
    get_progress_handler,
)
from unittest.mock import MagicMock

print('Streaming output imports successful')

# Test PersonaProgress
progress = PersonaProgress(index=1, name='Test', status='complete')
print(f'  PersonaProgress: index={progress.index}, status={progress.status}')

# Test GenerationProgress
gen_progress = GenerationProgress(total=3)
print(f'  GenerationProgress: total={gen_progress.total}, personas={len(gen_progress.personas)}')

# Test get_progress_handler
console = MagicMock()
handler = get_progress_handler(console=console, show_progress=False)
print(f'  Progress handler type: {type(handler).__name__}')

# Test callback flow
callback = handler.start(total=2, provider='anthropic', model='claude')
callback('Loading data...')
callback('Generating...')

mock_persona = MagicMock()
mock_persona.name = 'Test Persona'
handler.finish(personas=[mock_persona], input_tokens=100, output_tokens=50)

print('Streaming output display: OK')
"
```

**Expected:** All streaming classes work correctly

**Pass Criteria:**
- [ ] Streaming classes importable
- [ ] Progress tracking works
- [ ] Callback flow completes
- [ ] Handler factory works

---

## Test 12: Shell Completions (F-095)

**Command:**
```bash
# Test that completion generation doesn't error
persona --show-completion bash 2>/dev/null || echo "Bash completion available"
persona --show-completion zsh 2>/dev/null || echo "Zsh completion available"
persona --show-completion fish 2>/dev/null || echo "Fish completion available"
```

**Alternative Python test:**
```bash
python -c "
from persona.ui.completers import (
    complete_provider,
    complete_model,
    complete_workflow,
)

# Test provider completion
providers = list(complete_provider(''))
print(f'Provider completions: {len(providers)} providers')
assert len(providers) >= 3, 'Should have at least 3 providers'

# Test model completion (empty without context)
models = list(complete_model(''))
print(f'Model completions available: {len(models) >= 0}')

# Test workflow completion
workflows = list(complete_workflow(''))
print(f'Workflow completions: {len(workflows)} workflows')
assert len(workflows) >= 3, 'Should have at least 3 workflows'

print('Shell completions: OK')
"
```

**Expected:** Completions available for all shells, completer functions work

**Pass Criteria:**
- [ ] Shell completions don't error
- [ ] Provider completion works
- [ ] Workflow completion works

---

## Test 13: CLI Integration Test

**Command:**
```bash
# Test CLI help
persona --help

# Test version
persona --version

# Test check command
persona check

# Test cost command (dry run, no API needed)
persona cost --from data/synthetic/interviews/ --count 3 --provider anthropic

# Test config show
persona config show
```

**Expected:** All CLI commands work without errors

**Pass Criteria:**
- [ ] Help displays correctly
- [ ] Version shows correctly
- [ ] Check command works
- [ ] Cost estimation works
- [ ] Config show works

---

## Test 14: Smart `--from` Path Resolution

**Setup:**
```bash
# Create a test experiment with data
persona experiment create test-path-resolution
mkdir -p experiments/test-path-resolution/data
echo "name,feedback" > experiments/test-path-resolution/data/test.csv
echo "Alice,Great product" >> experiments/test-path-resolution/data/test.csv
```

**Test 1 - Direct path (should work):**
```bash
persona cost --from experiments/test-path-resolution/data/ --count 1
```

**Test 2 - Experiment name only (should resolve to experiments/<name>/data/):**
```bash
persona cost --from test-path-resolution --count 1
```

**Test 3 - Invalid path (should show helpful error):**
```bash
persona cost --from nonexistent-experiment --count 1 2>&1 | head -10
```

**Cleanup:**
```bash
persona experiment delete test-path-resolution --yes
```

**Expected:**
- Test 1: Works with full path
- Test 2: Resolves experiment name to data directory automatically
- Test 3: Shows clear error with paths tried

**Pass Criteria:**
- [ ] Direct path works
- [ ] Experiment name resolves correctly
- [ ] Error message shows resolution attempts
- [ ] Cleanup succeeds

---

## Test 15: Unit Tests

**Command:**
```bash
pytest tests/ -v --tb=short -x
```

**Expected:** All tests pass (2400+ tests)

**Pass Criteria:**
- [ ] All tests pass
- [ ] No unexpected warnings
- [ ] Coverage meets threshold (≥80%)

---

## Results Summary

| Test | Status | Notes |
|------|--------|-------|
| 1. Platform Independence | ⬜ | |
| 2. Wrapper Scripts | ⬜ | |
| 3. Path Manager | ⬜ | |
| 4. Built-in Help System | ⬜ | |
| 5. Documentation Generation | ⬜ | |
| 6. Synthetic Test Data | ⬜ | |
| 7. Global Configuration | ⬜ | |
| 8. SDK Documentation | ⬜ | |
| 9. Interactive Mode | ⬜ | |
| 10. TUI Configuration Editor | ⬜ | |
| 11. Streaming Output Display | ⬜ | |
| 12. Shell Completions | ⬜ | |
| 13. CLI Integration | ⬜ | |
| 14. Smart --from Resolution | ⬜ | |
| 15. Unit Tests | ⬜ | |

**Overall Result:** ⬜ Pass / ⬜ Fail

---

## Sharing Results

After completing all tests, share:

1. The completed results table above
2. Console output from any failed tests
3. Your environment details:
   - OS:
   - Python version:
   - Any issues encountered

Paste results to Claude for review.
