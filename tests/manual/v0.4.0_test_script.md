# Manual Test Script: v0.4.0 - Advanced Output + Conversation Scripts

This script verifies all v0.4.0 functionality. Execute tests in order and record results.

## Prerequisites

- Python 3.12+
- Git checkout of v0.4.0 tag
- No API keys required (tests use mock responses)

## Installation

```bash
# 1. Checkout the version
git checkout v0.4.0

# 2. Create fresh virtual environment
python3.12 -m venv .venv-test
source .venv-test/bin/activate  # On Windows: .venv-test\Scripts\activate

# 3. Install Persona with all dependencies
pip install -e ".[all]"

# 4. Verify installation
python -c "import persona; print(f'Persona v{persona.__version__}')"
```

**Expected:** Shows Persona v0.4.0

---

## Test 1: Version Check

**Command:**
```bash
python -c "import persona; print(persona.__version__)"
```

**Expected:** Shows 0.4.0

**Pass Criteria:**
- [ ] Shows 0.4.0

---

## Test 2: Formatter Registry (F-039)

**Command:**
```bash
python -c "
from persona.core.output import get_registry, OutputSection, SectionConfig

registry = get_registry()
print('Registered formatters:', list(registry.list_formatters().keys()))
print('Output sections:', [s.value for s in OutputSection])

# Test section presets
minimal = SectionConfig.minimal_preset()
full = SectionConfig.full_preset()
print('Minimal sections:', len([s for s in OutputSection if minimal.is_enabled(s)]))
print('Full sections:', len([s for s in OutputSection if full.is_enabled(s)]))
"
```

**Expected:** Shows registered formatters, output sections, and minimal has fewer sections than full

**Pass Criteria:**
- [ ] Shows registered formatters
- [ ] Shows output sections
- [ ] Minimal has fewer sections than full

---

## Test 3: Narrative Formatter (F-036)

**Command:**
```bash
python -c "
from persona.core.output import NarrativeFormatter, NarrativeConfig, Perspective
from persona.core.generation.parser import Persona

persona = Persona(
    id='test-001',
    name='Test User',
    goals=['Improve efficiency'],
    pain_points=['Manual processes'],
    behaviours=['Uses keyboard shortcuts'],
    quotes=['I need things to be faster'],
    demographics={'role': 'Developer', 'age': '30'}
)

# First person
config = NarrativeConfig(perspective=Perspective.FIRST_PERSON)
formatter = NarrativeFormatter(config)
result = formatter.format(persona)
print('=== First Person ===')
print(result[:500])
"
```

**Expected:** Generates first-person narrative ("I am...", "My goals..."), contains persona details

**Pass Criteria:**
- [ ] Generates first-person narrative ("I am...", "My goals...")
- [ ] Contains persona details

---

## Test 4: Table Formatter (F-037)

**Command:**
```bash
python -c "
from persona.core.output import PersonaComparisonTable, TableOutputFormat, TableConfig
from persona.core.generation.parser import Persona

personas = [
    Persona(id='p1', name='Developer Dan', goals=['Code faster'], pain_points=['Slow builds'], behaviours=[], quotes=[]),
    Persona(id='p2', name='Designer Diana', goals=['Better UX'], pain_points=['Poor tools'], behaviours=[], quotes=[]),
]

table = PersonaComparisonTable(personas)
print('=== Markdown Table ===')
print(table.format(TableOutputFormat.MARKDOWN))
print()
print('=== ASCII Table ===')
print(table.format(TableOutputFormat.ASCII)[:500])
"
```

**Expected:** Generates readable markdown table and ASCII art table with borders

**Pass Criteria:**
- [ ] Generates readable markdown table
- [ ] Generates ASCII art table with borders

---

## Test 5: Usage Scenario Generator (F-038)

**Command:**
```bash
python -c "
from persona.core.output import UsageScenarioGenerator, ProductContext
from persona.core.generation.parser import Persona

persona = Persona(
    id='test-001',
    name='Sarah',
    goals=['Find information quickly'],
    pain_points=['Too many clicks'],
    behaviours=['Power user', 'Uses search'],
    quotes=[],
    demographics={'role': 'Analyst'}
)

generator = UsageScenarioGenerator()
scenarios = generator.generate(persona)
print(f'Generated {len(scenarios)} scenarios')
for s in scenarios[:2]:
    print(f'- {s.scenario_name}: {s.narrative[:100]}...')
"
```

**Expected:** Generates usage scenarios with names and narratives

**Pass Criteria:**
- [ ] Generates usage scenarios
- [ ] Scenarios have names and narratives

---

## Test 6: README Generator (F-041)

**Command:**
```bash
python -c "
from persona.core.output import ReadmeGenerator, GenerationSummary, PersonaSummary
from datetime import datetime

summary = GenerationSummary(
    title='Test Generation',
    generated_at=datetime.now(),
    data_source='test.csv',
    persona_count=3,
    personas=[
        PersonaSummary(id='p1', name='Alice', summary='Power user'),
        PersonaSummary(id='p2', name='Bob', summary='Casual user'),
    ],
    model_used='claude-sonnet-4.5',
    experiment_id='exp-001'
)

generator = ReadmeGenerator()
readme = generator.generate(summary)
print(readme[:800])
"
```

**Expected:** Generates valid markdown README with generation metadata

**Pass Criteria:**
- [ ] Generates valid markdown README
- [ ] Contains generation metadata

---

## Test 7: Response Capture (F-042)

**Command:**
```bash
python -c "
from persona.core.output import ResponseCaptureManager, create_request_capture
import tempfile
import os

with tempfile.TemporaryDirectory() as tmpdir:
    manager = ResponseCaptureManager(tmpdir)
    session_id = manager.start_session('test-session')

    # Capture a request/response
    request = create_request_capture(
        provider='anthropic',
        model='claude-sonnet-4.5',
        messages=[{'role': 'user', 'content': 'Hello'}]
    )
    manager.capture_response(
        session_id,
        request,
        {'content': 'Hi there!'},
        latency_ms=150.0
    )

    manager.end_session(session_id)
    print(f'Session captured: {session_id}')
    print(f'Files created: {os.listdir(tmpdir)}')
"
```

**Expected:** Session created successfully, files created in output directory

**Pass Criteria:**
- [ ] Session created successfully
- [ ] Files created in output directory

---

## Test 8: Conversation Scripts (F-086)

**Command:**
```bash
python -c "
from persona.core.scripts import ConversationScriptGenerator, ScriptFormat, PrivacyConfig
from persona.core.generation.parser import Persona

persona = Persona(
    id='test-001',
    name='Maya Chen',
    goals=['Streamline workflows', 'Learn new tools'],
    pain_points=['Manual data entry', 'Slow systems'],
    behaviours=['Reviews dashboards daily', 'Prefers keyboard navigation'],
    quotes=['I wish I could automate this', 'Data drives my decisions'],
    demographics={'role': 'Product Manager', 'age': '32', 'experience': '8 years'}
)

generator = ConversationScriptGenerator()
result = generator.generate(persona, ScriptFormat.CHARACTER_CARD)

print(f'Blocked: {result.blocked}')
print(f'Privacy audit passed: {result.privacy_audit.passed}')
print(f'Leakage score: {result.privacy_audit.leakage_score:.3f}')
print()
print('=== Character Card (first 800 chars) ===')
print(result.output[:800])
"
```

**Expected:** Generation not blocked, privacy audit passes, character card contains abstracted content (not raw quotes)

**Pass Criteria:**
- [ ] Generation not blocked
- [ ] Privacy audit passes
- [ ] Character card contains abstracted content (not raw quotes)

---

## Test 9: Privacy Audit Verification

**Command:**
```bash
python -c "
from persona.core.scripts import PrivacyAuditor, PrivacyConfig
from persona.core.scripts.models import CharacterCard, Identity, PsychologicalProfile, CommunicationStyle, KnowledgeBoundaries, Guidelines, Provenance
from persona.core.generation.parser import Persona

# Create a persona with specific quote
persona = Persona(
    id='test-001',
    name='Test',
    goals=[],
    pain_points=[],
    behaviours=[],
    quotes=['I absolutely hate slow software systems']
)

# Create a card that leaks the quote directly
card = CharacterCard(
    id='script-001',
    identity=Identity(name='Test', title='Test'),
    psychological_profile=PsychologicalProfile(
        goals=[],
        motivations=[],
        pain_points=['I absolutely hate slow software systems'],  # Direct leak!
        personality_traits=[],
        flaws=[]
    ),
    communication_style=CommunicationStyle(
        tone='frustrated',
        vocabulary_level='professional',
        speech_patterns=[]
    ),
    knowledge_boundaries=KnowledgeBoundaries(knows=[], doesnt_know=[], can_infer=[]),
    guidelines=Guidelines(
        response_style='test',
        uncertainty_handling='test',
        character_maintenance='test',
        additional_rules=[]
    ),
    provenance=Provenance(source_persona_id='test-001')
)

auditor = PrivacyAuditor()
result = auditor.audit(card, persona)
print(f'Privacy audit passed: {result.passed}')
print(f'Blocked: {result.blocked}')
print(f'Leakage score: {result.leakage_score:.3f}')
print(f'Leakages detected: {len(result.leakages)}')
"
```

**Expected:** Privacy audit FAILS (passed=False), output is blocked, leakage detected

**Pass Criteria:**
- [ ] Privacy audit FAILS (passed=False)
- [ ] Output is blocked
- [ ] Leakage detected

---

## Test 10: Run Automated Tests

**Command:**
```bash
pytest tests/ -q
```

**Expected:** All 961 tests pass

**Pass Criteria:**
- [ ] All tests pass

---

## Results Summary

| Test | Status | Notes |
|------|--------|-------|
| 1. Version Check | ⬜ | |
| 2. Formatter Registry | ⬜ | |
| 3. Narrative Formatter | ⬜ | |
| 4. Table Formatter | ⬜ | |
| 5. Usage Scenario Generator | ⬜ | |
| 6. README Generator | ⬜ | |
| 7. Response Capture | ⬜ | |
| 8. Conversation Scripts | ⬜ | |
| 9. Privacy Audit Verification | ⬜ | |
| 10. Automated Tests | ⬜ | |

**Overall Result:** ⬜ Pass / ⬜ Fail

---

## Sharing Results

After completing all tests, share:

1. The completed results table above
2. Console output from any failed tests
3. Your environment details:
   - OS:
   - Python version:
   - Any issues encountered

Paste results to Claude for review.
